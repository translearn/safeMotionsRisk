{
  "batch_mode": "complete_episodes",
  "callbacks": "<class '__main__.CustomTrainCallbacks'>",
  "clip_param": 0.3,
  "entropy_coeff": 0.0,
  "env": "SafeMotionsEnv",
  "env_config": {
    "acc_limit_factor": 1.0,
    "acc_limit_factor_braking": 1.0,
    "action_mapping_factor": 1.0,
    "action_max_punishment": 0.4,
    "action_max_reward": 1.0,
    "action_preprocessing_function": null,
    "action_punishment_min_threshold": 0.95,
    "action_reward_min_threshold": 0.9,
    "action_reward_peak": 0.95,
    "activate_obstacle_collisions": false,
    "adaptation_max_punishment": 1.0,
    "ball_machine_mode": true,
    "braking_trajectory_max_punishment": 1.0,
    "braking_trajectory_max_torque_min_threshold": 0.8,
    "braking_trajectory_min_distance_max_threshold": 0.05,
    "check_braking_trajectory_collisions": false,
    "check_braking_trajectory_torque_limits": false,
    "closest_point_safety_distance": 0.01,
    "collision_avoidance_episode_early_termination_punishment": 0.0,
    "collision_avoidance_episode_termination_bonus": 0.0,
    "collision_avoidance_kinematic_state_sampling_mode": false,
    "collision_avoidance_kinematic_state_sampling_probability": 1.0,
    "collision_avoidance_low_acceleration_max_reward": 1.0,
    "collision_avoidance_low_acceleration_threshold": 0.1,
    "collision_avoidance_low_velocity_max_reward": 1.0,
    "collision_avoidance_low_velocity_threshold": 0.1,
    "collision_avoidance_mode": false,
    "collision_avoidance_moving_obstacles_max_reward": 0.0,
    "collision_avoidance_moving_obstacles_max_reward_distance": 0.3,
    "collision_avoidance_new_state_sample_time_range": null,
    "collision_avoidance_self_collision_max_reward": 0.0,
    "collision_avoidance_self_collision_max_reward_distance": 0.05,
    "collision_avoidance_static_obstacles_max_reward": 0.0,
    "collision_avoidance_static_obstacles_max_reward_distance": 0.1,
    "collision_avoidance_stay_in_state_probability": 0.3,
    "collision_check_time": 0.033,
    "end_max_torque_max_punishment": 1.0,
    "end_max_torque_min_threshold": 0.9,
    "end_min_distance_max_punishment": 1.0,
    "end_min_distance_max_threshold": 0.05,
    "episodes_per_simulation_reset": null,
    "experiment_name": "Space_state_action",
    "floating_robot_base": false,
    "human_network_checkpoint": null,
    "human_network_collision_avoidance_kinematic_state_sampling_probability": 0.3,
    "human_network_collision_avoidance_stay_in_state_probability": 0.3,
    "human_network_use_collision_avoidance_starting_point_sampling": false,
    "human_network_use_full_observation": false,
    "jerk_limit_factor": 1.0,
    "jerk_limit_factor_braking": 1.0,
    "klimits_version": "1.1.3",
    "log_obstacle_data": false,
    "logging_level": "WARNING",
    "m_prev": 0,
    "max_resampling_attempts": 0,
    "moving_object_active_number_single": 1,
    "moving_object_aim_at_current_robot_position": false,
    "moving_object_area_center": null,
    "moving_object_area_width_height": null,
    "moving_object_check_invalid_target_link_point_positions": false,
    "moving_object_random_initial_position": false,
    "moving_object_sequence": 0,
    "moving_object_speed_meter_per_second": 1.0,
    "moving_object_sphere_angle_min_max": null,
    "moving_object_sphere_center": null,
    "moving_object_sphere_height_min_max": null,
    "moving_object_sphere_radius": null,
    "no_self_collision": false,
    "normalize_reward_to_frequency": false,
    "normalize_reward_to_initial_target_point_distance": true,
    "obs_add_target_point_pos": true,
    "obs_add_target_point_relative_pos": true,
    "obs_planet_size_per_planet": 2,
    "obstacle_scene": 5,
    "obstacle_use_computed_actual_values": false,
    "online_trajectory_duration": 8.0,
    "online_trajectory_time_step": 0.1,
    "planet_mode": true,
    "planet_one_center": [
      -0.1,
      0.0,
      0.8
    ],
    "planet_one_euler_angles": [
      0.35,
      0,
      0
    ],
    "planet_one_period": 5.0,
    "planet_one_radius_xy": [
      0.65,
      0.8
    ],
    "planet_two_center": [
      -0.1,
      0,
      0.8
    ],
    "planet_two_euler_angles": [
      -0.35,
      0,
      0
    ],
    "planet_two_period": null,
    "planet_two_radius_xy": [
      0.75,
      0.8
    ],
    "planet_two_time_shift": -2.0,
    "pos_limit_factor": 1.0,
    "punish_action": true,
    "punish_adaptation": false,
    "punish_braking_trajectory_max_torque": false,
    "punish_braking_trajectory_min_distance": false,
    "punish_end_max_torque": false,
    "punish_end_min_distance": false,
    "punish_spline_max_cartesian_deviation": false,
    "punish_spline_max_deviation": false,
    "punish_spline_mean_cartesian_deviation": false,
    "punish_spline_mean_deviation": false,
    "ray_version": "1.4.1",
    "reward_action": false,
    "risk_check_initial_backup_trajectory": true,
    "risk_config_dir": "risk_networks/state_action/space/reaching_task",
    "risk_ground_truth_episodes_per_file": null,
    "risk_ignore_estimation_probability": 0.0,
    "risk_state_backup_trajectory_steps": null,
    "risk_state_config": 0,
    "risk_state_deterministic_backup_trajectory": false,
    "risk_state_initial_backup_trajectory_steps": 20,
    "risk_store_ground_truth": false,
    "risk_threshold": 0.065,
    "risk_use_backup_agent_for_initial_backup_trajectory_only": false,
    "robot_base_balancing_mode": false,
    "robot_scene": 0,
    "set_highest_action_to_one": false,
    "solver_iterations": 50,
    "starting_point_cartesian_range_scene": 1,
    "target_link_offset": null,
    "target_point_cartesian_range_scene": 0,
    "target_point_radius": 0.065,
    "target_point_reached_reward_bonus": 5.0,
    "target_point_relative_pos_scene": 0,
    "target_point_reward_factor": 1.0,
    "target_point_sequence": 0,
    "target_point_use_actual_position": false,
    "terminate_on_collision_with_moving_obstacle": true,
    "terminate_on_collision_with_static_obstacle": true,
    "terminate_on_self_collision": true,
    "torque_limit_factor": 1.0,
    "use_controller_target_velocities": true,
    "use_moving_objects": false,
    "use_splines": false,
    "use_target_points": true,
    "vel_limit_factor": 1.0
  },
  "evaluation_config": {
    "explore": false,
    "rollout_fragment_length": 1
  },
  "evaluation_interval": null,
  "evaluation_num_episodes": 624,
  "evaluation_num_workers": 0,
  "evaluation_parallel_to_training": false,
  "gamma": 0.99,
  "kl_coeff": 0.2,
  "kl_target": 0.01,
  "lambda": 1.0,
  "lr": 5e-05,
  "lr_schedule": null,
  "model": {
    "conv_filters": null,
    "custom_model": "keras_fcnet_last_layer_activation",
    "custom_model_config": {
      "fcnet_activation": "swish",
      "fcnet_hiddens": [
        256,
        128
      ],
      "last_layer_activation": "tanh",
      "log_std_range": [
        -1.375,
        0.0
      ],
      "no_log_std_activation": false,
      "vf_hiddens": null
    },
    "fcnet_activation": "swish",
    "fcnet_hiddens": [
      256,
      128
    ],
    "use_lstm": false
  },
  "normalize_actions": false,
  "num_gpus": 1,
  "num_sgd_iter": 16,
  "num_workers": 12,
  "rollout_fragment_length": 4160,
  "sgd_minibatch_size": 1024,
  "train_batch_size": 49920,
  "use_gae": true,
  "vf_clip_param": 10.0,
  "vf_loss_coeff": 1.0
}
